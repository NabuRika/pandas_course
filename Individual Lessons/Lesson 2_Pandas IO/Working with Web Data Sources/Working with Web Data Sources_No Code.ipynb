{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20a9b6e-381e-425f-831d-f3930214f19f",
   "metadata": {},
   "source": [
    "# <center> Web Data Sources </center>\n",
    "\n",
    "- [What are Web Data Sources](#section_1)\n",
    "- [Pandas read_html() Function](#section_2)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e635fd2-c069-46c9-8f86-b2f97af5b5d0",
   "metadata": {},
   "source": [
    "### What are Web Data Sources <a class=\"anchor\" id=\"section_1\"></a>\n",
    "\n",
    "Data professionals sometimes need to access external data sets from web pages to add in their analysis projects. \n",
    "\n",
    "For example, let's say you are working on a project and you need a data set about the population of each country. You do your research and find a table in a wikipedia page that has information about each country's population and the percentage of change.\n",
    "\n",
    "Let's see how we can scrape this table into a Pandas DataFrame and make use of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e509e6-a62f-45ad-b796-c3574cd67f03",
   "metadata": {},
   "source": [
    "### Pandas read_html() Function <a class=\"anchor\" id=\"section_2\"></a>\n",
    "\n",
    "Pandas library offers the [read_html()](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html) built-in function to allow users to parse HTML tables from web pages into a list of Pandas DataFrames. This functionality provides users with a fast way to access data tables embedded in web pages’ html code. \n",
    "\n",
    "In the example below, we will learn about how we can extract a specific table from the wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a5b1d8-dede-4436-9ed4-6ea9b00b868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594c8534-366f-40b3-ba40-0dc1920f6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the HTML table from the wiki page above\n",
    "\n",
    "\n",
    "# Display the data type\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a49470",
   "metadata": {},
   "source": [
    "We notice that the `web_data` variable is actually a Python list of 2 items.\n",
    "\n",
    "The function `read_html()` actually searches for any HTML tag that could be a data table and add that part into a list item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eae0f0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec4c9a",
   "metadata": {},
   "source": [
    "In order to find the correct table we need, the data analyst must first examine the items inside this list to find what they actually represent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d507c039-e4e5-42f8-8b79-bd3890064cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first item in the list\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71727a67",
   "metadata": {},
   "source": [
    "If we look closely, we notice there are some extra characters like brackets[], parentheses() and percentage signs % already embedded in this table. These extra characters should not be part of our DataFrame.\n",
    "\n",
    "Later in this course, we will learn how to clean this DataFrame in order to prepare the data for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de730c3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52c3cf",
   "metadata": {},
   "source": [
    "Let’s quickly explore some other items in our `web_data` list.\n",
    "\n",
    "If we select the second item, it seems to return another table with some messy html code and tags. Clearly this is not the one we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the second item in the list\n",
    "\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c6a72",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426fb92",
   "metadata": {},
   "source": [
    "If we try to find the third item, we would get an error because this is a list of 2 items only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353b5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the third item in the list\n",
    "\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ace6c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f295cc",
   "metadata": {},
   "source": [
    "In summary, the Pandas `read_html()` function can help us quickly extract web data instead of using external python web data scraping libraries such as `beautifulsoup` and `selenium`. \n",
    "\n",
    "However, there will be scenarios where Pandas struggles with web scraping and we need to resort to specilized libraries. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
