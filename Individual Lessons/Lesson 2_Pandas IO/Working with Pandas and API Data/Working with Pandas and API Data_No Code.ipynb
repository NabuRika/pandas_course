{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0accecb4-062f-429d-9541-b3ad759d9e7c",
   "metadata": {},
   "source": [
    "# <center> Working with Pandas and API data </center>\n",
    "\n",
    "- [What is an API](#section_1)\n",
    "- [Convert API Data into a Pandas Object](#section_2)\n",
    "- [Use Pandas built-in functions to send and receive API data](#section_3)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5ba0d-3fdd-463c-b97e-44717036751a",
   "metadata": {},
   "source": [
    "### What is an API <a class=\"anchor\" id=\"section_1\"></a>\n",
    "\n",
    "When working on daily tasks, data professionals often need to access data from third-party APIs. This system architecture is widely used in modern applications especially when the data source is continuously updating such as stock market price data, weather data and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf664dc",
   "metadata": {},
   "source": [
    "The term API is short for `Application Programming Interface`. It’s a type of interface or a connection layer that allows computer programs to communicate and talk to each other. \n",
    "\n",
    "Imagine if you have a weather APP on your smartphone and you want to check the weather forecast for the upcoming weekend.\n",
    "\n",
    "Since weather data is always changing, the client or application will need to request that information from a third party database. \n",
    "\n",
    "The server will then process the request and send back the needed response to the client through API.\n",
    "\n",
    "Therefore, the API layer in the middle will be responsible for organizing that communication, which is technically known as `request` and `response`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d18b5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400b843-af09-43f1-b506-4626588cf590",
   "metadata": {},
   "source": [
    "### Convert API Data into a Pandas Object <a class=\"anchor\" id=\"section_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afefdb4-2051-44e4-b72e-b790600f65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas library\n",
    "\n",
    "\n",
    "# Import requests library to handle API connection\n",
    "\n",
    "\n",
    "# Import pprint library to display data structures\n",
    "\n",
    "\n",
    "# Initialize Pretty Printer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d9d71",
   "metadata": {},
   "source": [
    "In the examples below, we will be using the [Open Notify](http://open-notify.org/Open-Notify-API/) API. It is designed to provide continuous updates about the International Space Station or ISS current location and crew members onboard. The json file about astronauts is stored on this [link](http://api.open-notify.org/astros.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d95959-6dbd-4ba4-80d2-dd4ebe267ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the API query using requests library\n",
    "\n",
    "\n",
    "# Convert response data into JSON format\n",
    "\n",
    "\n",
    "# Examine the response data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e194c",
   "metadata": {},
   "source": [
    "We notice that the response data is basically a Python dictionary of several key - value pairs. And the dictionary tells us there are currently 10 crew members on board the international space station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c3a8a-6b4f-405b-a477-e68c4ed1af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of astronauts currently aboard the ISS\n",
    "\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da229d6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8f9a0-00e7-4ae7-ad0d-73f1193402c3",
   "metadata": {},
   "source": [
    "### Use Pandas Built-In Functions to Send and Receive API Data <a class=\"anchor\" id=\"section_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38dd390",
   "metadata": {},
   "source": [
    "Google BigQuery is a cloud based data warehouse that allows users to perform data analytics and machine learning services using SQL. \n",
    "\n",
    "If you are new to BigQuery, you can get a free sand-box account to explore the platform and follow this example. \n",
    "\n",
    "Using my Google account, I created a new project called `pandas-io` and an empty Dataset called `demo`. \n",
    "\n",
    "The term data set here is more like a logical container of small data files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478b489",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "<br>\n",
    "<br>\n",
    "Pandas has split off Google BigQuery support into the separate package pandas-gbq.\n",
    "\n",
    "If you don’t already have this library, you need to install it using the `pip command`, and you also need a valid BigQuery account. Use the BigQuery sandbox to try the service for free.\n",
    "\n",
    "We will be working with 2 main Pandas functions, [to_gbq()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_gbq.html) and [read_gbq()](https://pandas.pydata.org/docs/reference/api/pandas.read_gbq.html) to send and receive data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6915f",
   "metadata": {},
   "source": [
    "### Pandas to_gbq() Function <a class=\"anchor\" id=\"section_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3554e-55ec-4cd3-8684-8a178caa683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library for Pandas Google BigQuery support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f37f945",
   "metadata": {},
   "source": [
    "Notice the important parameters that we need to assign in the following example:\n",
    "\n",
    "- `destination_table` will be the name of table in the platform\n",
    "\n",
    "- `project_id` will be the name of the project we created earlier in our account\n",
    "\n",
    "- `if_exists` parameter will give us some warning messages if the DataFrame we are uploading already exists in our account \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434102b-2ffa-4bed-a5f4-2d397b0812af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to_gbq() method to upload a DataFrame into BigQuery platform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f8bce2",
   "metadata": {},
   "source": [
    "Here, if we switch to our sand-box account, we can see our astronauts table with all its values already on the cloud. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a565f1",
   "metadata": {},
   "source": [
    "Back to the example above, if we try to run the same code cell one more time, it would give us an error.\n",
    "\n",
    "Basically, it tells us that we can not send this DataFrame to the cloud because we already have a table with the same name in our project. \n",
    "\n",
    "It suggests that we change the `if_exisit` parameters to one of the other options: `replace` OR `append`.\n",
    "\n",
    "Let's try to do that and change it to `replace`, then we run the the cell again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to_gbq() method to upload a DataFrame into BigQuery platform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e1ee04",
   "metadata": {},
   "source": [
    "It seems to be successful this time.\n",
    "\n",
    "**QUIZ**\n",
    "<br>\n",
    "Can you guess what would happen if we use `append`? Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb173f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69588513",
   "metadata": {},
   "source": [
    "### Pandas read_gbq() Function <a class=\"anchor\" id=\"section_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5ad4c",
   "metadata": {},
   "source": [
    "Now that we have our data already in the cloud, let's see what else we can do.\n",
    "\n",
    "In a real life scenario, you will probably upload a large dataset with thousands of rows and columns, then you can use the BigQuery platforms to do your analysis.\n",
    "\n",
    "For us today, we will do a simple example to run SQL query with a `groupby` statement.\n",
    "\n",
    "Basically we want to know the number of people within each spacecraft in our astronauts table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query from pandas-io.demo.astronauts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use read_gbq function to read the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d872b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e903c32",
   "metadata": {},
   "source": [
    "You can also use other parameters such as `index_col` to assign the DataFrame index.\n",
    "\n",
    "Give it a try and see what would happen!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
