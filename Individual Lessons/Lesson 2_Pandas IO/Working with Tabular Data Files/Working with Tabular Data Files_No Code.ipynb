{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14c054ad-7d51-426c-b1dd-4549ac9dcb17",
   "metadata": {},
   "source": [
    "# <center> Working with Tabular Data Files </center>\n",
    "\n",
    "- [What is Tabular Data Format](#section_1)\n",
    "- [Pandas read_csv() Function](#section_2)\n",
    "- [Pandas read_excel() Function](#section_3)\n",
    "- [Pandas read_sql() Function](#section_4)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b97cb1-1e26-440d-98e5-8e4a4f1e0282",
   "metadata": {},
   "source": [
    "### What is Tabular Data Format <a class=\"anchor\" id=\"section_1\"></a>\n",
    "\n",
    "\n",
    "Tabular data is usually structured into rows and columns and presented in various file formats including CSV files, Excel spreadsheet, and SQL tables. Tabular files can be accessed from the local computer or online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f469507",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432f6e9-b5b4-4434-971b-6a4542364bdb",
   "metadata": {},
   "source": [
    "### Pandas read_csv() Function <a class=\"anchor\" id=\"section_2\"></a>\n",
    "\n",
    "Pandas library provides the [read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) built-in function to read a comma-separated values (csv) file into DataFrame.\n",
    "\n",
    "The dataset file we are going to use is stored online on [FiveThirtyEight](https://github.com/fivethirtyeight/data) Github repo. This repo has a good collection of publicly available datasets. \n",
    "\n",
    "The dataset we are looking at today is alcohol-consumption around the world from the repo link above. Let's read it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfdcbe4d-4c3f-4231-a582-2a84af949043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7481f69f-3d5b-4e62-abf7-f48b158f0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an alcohol-consumption dataFrame using read_csv() function from the repo link above\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b1e0a9",
   "metadata": {},
   "source": [
    "We notice this dataset has about 193 rows and 5 different columns. \n",
    "\n",
    "Also notice, the default behavior of the Pandas library is to display the top and bottom 5 rows of the DataFrame object and indicate the hidden rows in the middle part of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a57c05",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd352ad",
   "metadata": {},
   "source": [
    "In real life scenarios, data professionals may sometimes need to access an extremely large dataset file with thousands of rows and columns.\n",
    "\n",
    "In this case, we can make use of some of the optional parameters to only select a specific subset of the large data file.\n",
    "\n",
    "This can be very useful especially if you are moving large datasets through the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a64f6c-c12d-4ec6-b75a-05e08be0741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an alcohol-consumption dataFrame using read_csv() function from the repo link above. Filter rows and columns using function parameters\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a85e2",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620abd7",
   "metadata": {},
   "source": [
    "Another great parameter available to read_csv() function is the `index_col`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ee2ce8-781f-4f98-b1bd-cc2c4fd732bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an alcohol-consumption dataFrame using read_csv() function from the repo link above. Assign one column as DataFrame index using label\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d823c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537cdcec-6c10-49fe-a4ac-4edf18c4c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an alcohol-consumption dataFrame using read_csv() function from the repo link above. Assign one column as DataFrame index using the numeric position\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18a759",
   "metadata": {},
   "source": [
    "Notice how we can change the index value to be either the columnâ€™s numeric position or label. \n",
    "\n",
    "In both examples above, the results are the same as we see the same column is now assigned as the DataFrame index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c37e75",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4bd01-bdd0-492f-b3d0-6fad5a826632",
   "metadata": {},
   "source": [
    "### Pandas read_excel() Function <a class=\"anchor\" id=\"section_3\"></a>\n",
    "\n",
    "Another commonly used tabular data format is spreadsheets. Pandas library provides the [read_excel()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) built-in function to access Microsoft Excel spreadsheet files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a08dfb",
   "metadata": {},
   "source": [
    "In the following example, we will use an Excel file that is already stored on our local machine. This file is also available in the course repo.\n",
    "\n",
    "There are 2 datasets stored in the sheet names: `short_list`and `long_list`. The short one has a list of 5 countries while the long one has a list of 14 countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0323b9cb-18b9-4f09-98f9-33944f3db903",
   "metadata": {},
   "source": [
    "Notice how the [read_excel()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) example makes use of the `sheet_name` parameter to tell the system which sheet name contains the needed dataset. For a complete list of all parameters for each built-in function, check the Pandas official documentation to know more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178cc0c9-d9fa-4f7f-a3a4-ff2cc5ce95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame object using read_excel() function. Use parameter to identify dataset\n",
    "\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "304608f3-6d98-4c5f-a553-b252e40dc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame object using read_excel() function. Use parameter to identify dataset\n",
    "\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65916d54",
   "metadata": {},
   "source": [
    "Similar to what we learned before, the `read_excel()` function also has the optional `index_col` parameters.\n",
    "\n",
    "**Quiz**:<br>\n",
    "Can you use the parameter `index_col` to assign one of the columns to be the DataFrame index?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13e3b5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c72928-bd35-4c12-99ad-59beaa16f3dd",
   "metadata": {},
   "source": [
    "### Pandas read_sql() Function <a class=\"anchor\" id=\"section_4\"></a>\n",
    "\n",
    "Another common scenario is to query relational database tables using SQL language. Obviously, you would need to provide the necessary credentials and metadata to establish a connection with the database server. You can then apply [read_sql()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html) function to pass the SQL query and load the result into a Pandas DataFrame object. \n",
    "\n",
    "To simulate this scenario, the following code will create a local database using the Python SQLite engine. We will then use Pandas to access the data using SQL queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac55496-ca52-4282-aea1-23feb2fe79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SQLite library\n",
    "\n",
    "\n",
    "# Assign the database name\n",
    "\n",
    "\n",
    "# Create the database file\n",
    "\n",
    "\n",
    "# Establish a connection with the database file\n",
    "\n",
    "\n",
    "# Create a database table\n",
    "\n",
    "\n",
    "# Add some data\n",
    "\n",
    "\n",
    "# Commit changes and close the connection\n",
    "\n",
    "\n",
    "# Close the connection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe9f137-5e9b-45a6-9b0a-93f91f035c00",
   "metadata": {},
   "source": [
    "The relational database name `local_db_example.db` should appear as an external file in the same location with your notebook. The database file already includes dummy data describing employee details. The following code queries the data into a Pandas DataFrame object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9294dce",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bcbde0-c535-47fe-bc03-34122130c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the database name\n",
    "\n",
    "\n",
    "# Establish a connection with the database file\n",
    "\n",
    "\n",
    "# Use Pandas function to pass SQL query and create a DataFrame object\n",
    "\n",
    "\n",
    "# Print the generated DataFrame\n",
    "\n",
    "\n",
    "# Close the connection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e13e6f-403a-40cb-9e51-85e01873a8fc",
   "metadata": {},
   "source": [
    "In the above example, we created a local database file and used the Pandas library to query the data using SQL, and passed the results into a Pandas DataFrame object. In more practical examples, you may need to query data from relational databases that are stored on remote servers or in the cloud.\n",
    "\n",
    "**[Back to Top](#title)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
