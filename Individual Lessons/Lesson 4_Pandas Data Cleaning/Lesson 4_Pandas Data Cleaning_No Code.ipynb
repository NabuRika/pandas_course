{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0fecf9-b2b6-4ce5-9db6-14fad4aa4db9",
   "metadata": {},
   "source": [
    "# <center> Pandas Data Cleaning </center>\n",
    "\n",
    "- [Split DataFrame Columns](#section_1)\n",
    "- [Text Cleaning with Regular Expressions](#section_2)\n",
    "- [Update Column Datatypes](#section_3)\n",
    "- [Drop Rows and Columns](#section_4)\n",
    "- [Rename Columns](#section_5)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af158e-e12c-480b-9c9b-887f373b9931",
   "metadata": {},
   "source": [
    "Many real-life datasets come with problems such as missing values, wrong datatype, and bad formatting. Data professionals usually need to spend lots of time correcting these issues before the dataset becomes ready for analysis. Luckily, Pandas library comes with a set of built-in functions to help users fix these issues. In this section, we will learn how to use Pandas to identify and correct some common data quality issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f0960-47b0-4ef3-af3a-0ba60a2c09a9",
   "metadata": {},
   "source": [
    "## Data Cleaning with Pandas\n",
    "\n",
    "To demonstrate the data cleaning process, we will use a toy DataFrame about countries. Each country has different piece of information such as name, population, size, and independence date as shown in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe5392c-f5ea-4440-9de7-e798c33a34c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6bc8753-e2a1-44d5-a249-b427eb986c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries. Refer to lesson video for details.\n",
    "\n",
    "# Create a Pandas DataFrame from a list of dictionaries\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb34fec-ee49-4240-9ad3-dfeebbe57468",
   "metadata": {},
   "source": [
    "Looking at our DataFrame, we notice the information about the country `New Zealand` was repeated twice in rows 1 and 5. Also, we notice the `Country Area` has values in both `km2` and `mi2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996165dc-8811-427d-b4c3-f7e6f7f7664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of the DataFrame columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb58d7-68ea-4784-a439-74ac4abd5975",
   "metadata": {},
   "source": [
    "Examining the DataFrame using the [`info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) attribute shows that both `country area` and `independence day` columns were incorrectly assigned the `object` datatypes.\n",
    "\n",
    "In order to clean up the data for further analysis, we need to perform the following steps:\n",
    "\n",
    "* Split the `Country Area` values into two columns for `km2` and `mi2` respectively\n",
    "* Remove any non-numeric characters from the area values\n",
    "* Change the `Country Area` and `independence day` columns to the correct data types\n",
    "* Drop unwanted rows and columns\n",
    "* Rename all the columns to have lower case letters separated by underscores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52cc03-750a-46bb-b93e-fb05ffccd539",
   "metadata": {},
   "source": [
    "### Split DataFrame Columns <a class=\"anchor\" id=\"section_1\"></a>\n",
    "\n",
    "The `Country Area` column is represented in both square kilometers and square miles. The `mi2` values are included within `parentheses ()` and there is an `empty space` between the square kilometers and square miles values. Therefore, we can use the Pandas built-in [`split()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) function to separate these values into new different columns as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e116f3-cfd9-47ef-bfd5-327b72674395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply split() function to separate values into 2 different columns\n",
    "\n",
    "# Display DataFrame head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823996e-4491-40a3-b447-4344b4015bba",
   "metadata": {},
   "source": [
    "The first part of the code `countries[['Area km2','Area mi2']]` on the left side of the equal `=` sign creates two new columns in our DataFrame. Then on the right side of the equal sign, we first identify the column country area in kilometers and miles, and we apply the [`split()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) function to split strings around the given separator.\n",
    "\n",
    "Notice that anytime we need to handle the data as a string, we need to identify the column name, then we put a `dot (.)` string and then one of many possible text functions.\n",
    "\n",
    "In this case, the function splits the text into two different pieces, and one of the important parameters to pass is the string that we will use to split the value. As we note that there is always a `space` between the two values, we will use that as our splitting criteria. \n",
    "\n",
    "The last parameter the `expand equals True` is what we use to split these values and assign them into two new columns at the same time.\n",
    "\n",
    "As a result, you will notice that the column `Country Area km2 (mi2)` was split into two new columns - `Area km2` and `Area mi2`.\n",
    "\n",
    "However, we still notice there are some extra strings such as the parentheses and commas that need further cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245ed7e-c4e6-4743-a0a1-5115d69c4b2c",
   "metadata": {},
   "source": [
    "### Text Cleaning with Regular Expressions <a class=\"anchor\" id=\"section_2\"></a>\n",
    "\n",
    "After we split the `Country Area` into two separate columns, we need to continue our work to convert these values into numeric format by removing any non-numeric characters such as parentheses and commas from the newly created columns `Area km2` and `Area mi2`.\n",
    "\n",
    "To do that, we can use the built-in [`replace()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html) function to replace occurrences of specific patterns in a given series with some other string. The function will take the first parameter as the targeted string or regular expression pattern, and the second parameter as the replacement value. The following code demonstrates how we replace any non-numeric values using the regular expression `(\\D+)` within the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b719a077-eab3-4f2d-9ea8-10d2563024db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply regular expression patterns to replace any non-numeric values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309faf8",
   "metadata": {},
   "source": [
    "Pay attention that in some cases, you may see a [`warning`](https://stackoverflow.com/questions/66603854/futurewarning-the-default-value-of-regex-will-change-from-true-to-false-in-a-fu) about future changes in how the [`replace()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html) function would handle regular expressions. This warning can be removed by applying the `regex=True` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1959cb8-8269-497c-92db-6532143eb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae641310",
   "metadata": {},
   "source": [
    "So far, by looking at the result, we have converted the country area column into two new columns, and we further cleaned and removed all the non-numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f47cc-0680-4ebe-a97a-d97fac5739c2",
   "metadata": {},
   "source": [
    "## Update Column Datatypes <a class=\"anchor\" id=\"section_3\"></a>\n",
    "\n",
    "Once we separated and cleaned up the country area into the proper format, we can move forward to assign the country area and independent day columns to the correct data types. To do that, we will make use of Pandas [`astype()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html) function to pass a Python dictionary representing the name of each column and the corresponding data type as shown in this code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f480920d-8adc-483c-9b98-93258999a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change specific columns' data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a51786c",
   "metadata": {},
   "source": [
    "We see for the new columns about the `Country Area`, we assigned them the `integer` data type; while the column `independence day` is assigned the `date` data type. \n",
    "\n",
    "The code runs without any problem which means the data types were correctly changed and reassigned. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b68b5-1450-4f94-a844-7391ebeca684",
   "metadata": {},
   "source": [
    "## Drop Rows and Columns <a class=\"anchor\" id=\"section_4\"></a>\n",
    "\n",
    "Any data processing task would often include removing duplicate records or unwanted columns. In our countries DataFrame, we notice such cases as repeated rows for `New Zealand`. As we already split the country area into two new columns, there is no need to keep the old country area column too.\n",
    "\n",
    "The Pandas library provides us with built-in functions to remove any unwanted records and columns.\n",
    "\n",
    "The [`drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) function needs to specify the corresponding axis on which the action will be applied.\n",
    "\n",
    "0: to indicate the action will be taken at the `row-level`; \n",
    "<br>\n",
    "1: to indicate the action will be taken at the `column-level`\n",
    "\n",
    "The following code demonstrates how to use the [`drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) function to remove unwanted rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7238307f-7166-440d-8f73-d976adca1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove the old country area column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ecd8cb",
   "metadata": {},
   "source": [
    "Note above that if we ignore the `in_place` parameter, the execution of this function will only occur during runtime, which means it will not be permanent. That's why we need to set the `inplace = True` if we want to make the changes permanent.\n",
    "\n",
    "Let's see how we can drop unwanted rows below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af2b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove duplicate row for New Zealand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c412608b-3137-4cb0-b85f-7e0aece86a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28945d0",
   "metadata": {},
   "source": [
    "This time we specified the record index five and assigned axis value 0 to indicate that we wanted to remove the record. To make that change permanent, we assigned the inplace parameter to True. The cell was run successfully which means the record was removed successfully. \n",
    "\n",
    "This can be a very practical way to remove a small number of records that we may be already aware of. However, imagine you have 10 repeated records. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a4bbde-4615-4197-a8cc-bef065da9107",
   "metadata": {},
   "source": [
    "The Pandas library provides another way to remove large numbers of unwanted records.\n",
    "\n",
    "Instead of using the [`drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) function multiple times, we can make use of the [`Pandas drop_duplicates()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html) to remove all duplicate rows at the same time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af65c48-7ac3-451e-b22d-6cd6847e35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated records using drop_duplicates() function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d35b496-cf4c-49bc-b1c2-324f3a4e6677",
   "metadata": {},
   "source": [
    "## Rename Columns <a class=\"anchor\" id=\"section_5\"></a>\n",
    "\n",
    "Now we move to the last item on our to do list which is to change the column labels by following the naming convention.\n",
    "\n",
    "This typically means to have all the title names in small letters separated by an underscore. \n",
    "\n",
    "To achieve this, we can make use of the Pandas [`rename()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html) function by passing a dictionary with current and new column names as shown in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86cc817e-62c0-466a-a94b-5ed529717c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0805057-ff99-4b6a-b075-0e6fe2cfdf6b",
   "metadata": {},
   "source": [
    "Now we can run the [`info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) method to print a nice summary of the DataFrame and examine all the changes applied to this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f4240c8-bd94-48c2-b94c-f86d8554b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c501635",
   "metadata": {},
   "source": [
    "Looks like we have successfully changed the column names. We have the correct data types and there is no unnecessary columns.\n",
    "\n",
    "Let's have a final look at our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7244a29-c868-4f93-b927-ec08590f08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e3c0ea",
   "metadata": {},
   "source": [
    "We can see now it looks squeaky clean!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fa0bc",
   "metadata": {},
   "source": [
    "In this lesson we have learned about the most common and widely used data cleaning techniques that data professionals use in their daily work. Want to learn more? Stay tuned!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
