{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a05f07-fd4f-41cf-b4fc-2263a7b9dfc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center> Pandas Merging & Joining Data </center>\n",
    "\n",
    "- [Simple Joining with Concat Function](#section_1)\n",
    "- [Complex Joining with Merge Function](#section_2)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d6689-3089-40c4-a144-11564be62b5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pandas Merging & Joining Data <a class=\"anchor\" id=\"section_0\"></a>\n",
    "\n",
    "One of the common tasks for any data professionals is to collect and aggregate multiple data sources. Very often, these data sources are stored separately at different database systems and possibly different locations. The advantage of the aggregation process is to allow us to further our analysis and extract meaningful insights.\n",
    "\n",
    "For instance, let's say you are working on a project to analyze the impact of a sports game on food and beverage sales. \n",
    "\n",
    "Typically, you will need different datasets such as sports game timetable, sports team performance, sport venues as well as sales revenue from different vendors. In real-life, these datasets are likely stored at different sources, some online and some on your local computer.\n",
    "\n",
    "In this section, we will learn the two most common ways to combine DataFrames in the Pandas library:\n",
    "\n",
    "* **pd.concat([DataFrame1, DataFrame2]): Simple combining two or more Pandas dataframes in a column-wise or row-wise approach.**\n",
    "\n",
    "* **pd.merge([DataFrame1, DataFrame2]): Complex column-wise combining of Pandas dataframes in a SQL-like way.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff13527-a892-4a30-9a3c-f27990db940b",
   "metadata": {},
   "source": [
    "### Simple Joining with Concat Function <a class=\"anchor\" id=\"section_1\"></a>\n",
    "\n",
    "The [concat()](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) function is used to add together one or more DataFrames. To demonstrate how it works, we will use the function to combine multiple toy DataFrames about popular sports tournaments like FIFA Soccer World Cup and Rugby World Cup. Each dataset has different pieces of information such as winning team, host country, attendance size as shown in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce927516-1717-4d1f-9454-432fa9aa25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ca31d4-a800-46bf-a0f5-2b24e380dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe about FIFA World Cup Winning Teams. Refer to lesson video for details.\n",
    "\n",
    "# Display DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23151438",
   "metadata": {},
   "source": [
    "And in the same way, we create the rugby world cup tournament dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cea0be4-3eb4-48bc-b9c6-5bff80488109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe about Rugby World Cup Winning Teams. Refer to lesson video for details.\n",
    "\n",
    "# Display DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc573f-1a1a-426f-9b35-2a385541851e",
   "metadata": {},
   "source": [
    "We first noticed the DataFrames above have some common information such as the year of the event, the winning team name, and the host country. However, the Rugby World Cup dataset has two extra columns: venue and attendance.\n",
    "\n",
    "Let's try to create a large dataset with all winning FIFA and Rugby world cup teams. The code below demonstrates how to use all the common column names to stack the two DataFrames on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbbd3e86-a0df-4c3c-b366-5b87492c67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the 2 DataFrames using the concat() method\n",
    "\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b63a0-34ce-4232-b818-d1677e83f177",
   "metadata": {},
   "source": [
    "We created a new DataFrame object called `df_teams` with 12 records from the two parent datasets. However, the resulting DataFrame raises some issues. \n",
    "\n",
    "- First, it becomes impossible to identify if a given team was part of the original Rugby or Soccer datasets;\n",
    "- Second, the new DataFrame object inherits the original index values from the parent datasets. This behaviour can be controlled by adjusting the [concat()](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) function parameters. The keys parameter can be used to track the data source by adding extra index values to the new DataFrame as shown in the example below. This feature would allow us to query and access specific subsets of the DataFrame using the newly assigned index value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3138e",
   "metadata": {},
   "source": [
    "The good thing is, we can fix these issues by changing some of the parameters in the [concat()](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) function. The parameter `keys` is used to highlight the source of the DataFrame, so we will be able to know which of these records belong to the rugby world cup or the fifa world cup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31fbc412-0b5b-4068-8afe-a6e4b7ec49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data source index values to the new DataFrame\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d079370",
   "metadata": {},
   "source": [
    "As you can see, the parameter takes a list of values to be added to the DataFrame index. This part is now called a multi-level index value which is something we will be learning more in future lessons.\n",
    "\n",
    "From the result, we can see very clearly which records belong to the rugby or fifa world cup. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f4da40-aeff-4399-a21e-a15488a7f654",
   "metadata": {},
   "source": [
    "In another scenario, we may prefer the new DataFrame to have totally new index values. This option can be achieved by setting the `ignore_index` parameter to `True` as shown in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a20a48c-7cbe-426e-adaa-ea3307454f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore old index values in the new DataFrame\n",
    "\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a10606e-7a6a-435d-b22a-ef296de34cce",
   "metadata": {},
   "source": [
    "The [concat()](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) function also allows us to combine multiple datasets even with little or no common values among them. The newly generated dataset will include all columns from the original DataFrame, with missing values replaced with `null` or `NaN` as shown in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db6c535b-a248-4774-ba12-c2c0a6420e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat two DataFrames to include all original columns\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b45d4-4419-478f-8df5-5dde084bde0e",
   "metadata": {},
   "source": [
    "The examples above demonstrate how the Pandas [concat()](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) function can create new datasets by adding DataFrame objects on top of each other (row axis). The function also provides the possibility to add the DataFrames sideways (column axis). This option is controlled using the axis parameter when it's set to 0 or 1 as shown in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d8e2b4b-536a-43f0-ab54-acbeb01f72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat two DataFrames to include all original columns aligned horizontally\n",
    "\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa9c4b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb440445-1e30-4278-ad68-85f2a72e69cd",
   "metadata": {},
   "source": [
    "### Complex Joining with Merge Function <a class=\"anchor\" id=\"section_2\"></a>\n",
    "\n",
    "Pandas [merge()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) provides the functionality to join DataFrame and Series objects in a way similar to relational database operations. Users who are familiar with merging datasets using SQL may find the merge function easy to use. \n",
    "\n",
    "You will notice that there is a focus on the use of key values and how similar values on both sides help to decide how to merge the datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6385880",
   "metadata": {},
   "source": [
    "As usual, let’s create some dummy data sets to practice with. The first dataset is called departments and it consists of three columns and four rows while the second dataset is called employees with three columns and five rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16aca857-4d25-4ff3-9d92-fa9e327ae627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create employees dataset\n",
    "\n",
    "\n",
    "# Create departments dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1727ed79-bca7-4b4e-9dc5-0057b063935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display df_departments \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22ac955-57dc-4cb1-9f16-5d0559bd2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display df_employees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb5b8b",
   "metadata": {},
   "source": [
    "We notice the two datasets have different columns such as `department_name` and `department_location`, and `employee_name` and `salary`. \n",
    "\n",
    "However, we also notice a common column in both DataFrames called `department_id`. And inside that column there are some identical values in both datasets, such as `D1` and `D2`, as well as some different values such as `D4` that is only available in the departments dataset and `D6` that is only available in the employees dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67a9749-f1e5-4250-8f98-d457342c23be",
   "metadata": {},
   "source": [
    "To join the two DataFrame objects using the  [merge()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) function, we can use a set of parameters to identify common values, joining type, and source object. \n",
    "\n",
    "* `on`: This parameter can be used if the common column has the same name in both DataFrames\n",
    "* `left on`: Identify the joining column in the left DataFrame\n",
    "* `right on`: identify the joining column in the right DataFrame\n",
    "* `indicator`: Add an extra column to the joined DataFrame to show the source of each row\n",
    "* `how`: Identify the joining type as one of four possible options [inner, left, right, outer]. \n",
    "\n",
    "The following code will merge the two tables using the key column and the default inner joining method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a759bcb-a853-4ba3-9829-fd951f8d510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames using the common column\n",
    "\n",
    "\n",
    "# Display the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b95f32",
   "metadata": {},
   "source": [
    "From the result, we can see only 4 rows were selected above. These are the records with the `department_id` values `D1`, `D2`, `D3` and originally appeared on both the left and right datasets. This is essentially how the SQL inner join works. \n",
    "\n",
    "We also notice how the indicator parameter gives us the source of the records. That means these 4 records appear on both sides of the joining DataFrames. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d19ea7",
   "metadata": {},
   "source": [
    "Now let's try to change the `how` parameter from the default \"inner\" to \"outer\" join to see what's the difference, and we can check if we can get all the records in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e20849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames using outer join\n",
    "\n",
    "\n",
    "# Display the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afafee7c",
   "metadata": {},
   "source": [
    "Here we see we joined both the common and non-common values of the records. \n",
    "\n",
    "The records with (`D1` to `D3`) appear to be coming from both original datasets while `D4` record appears only from the right “departments” dataset, and don't have any values for `employee_name`, while `D6` appears from the left “employees” dataset and doesn't have any value for `department_name`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58d691",
   "metadata": {},
   "source": [
    "Now you can try to practice some of these parameters on your own by changing the indicator from true to false and other joining options to learn the ins and outs of the merge function. \n",
    "\n",
    "These two functions [merge()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) and [concat()](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)  represent the most commonly used methods to join data sets in the pandas library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
